{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import faiss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"movies_list.csv\")\n",
    "df['genre'].value_counts()\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genre\n",
       "драма                                 5773\n",
       "комедия                               1796\n",
       "боевик                                1684\n",
       "документальный                        1603\n",
       "мультфильмы                           1502\n",
       "биографический                         803\n",
       "детектив                               777\n",
       "триллер                                441\n",
       "война                                  378\n",
       "мелодрама                              206\n",
       "ужасы                                  190\n",
       "приключения                            131\n",
       "вестерн                                115\n",
       "семейный                                71\n",
       "музыка                                  69\n",
       "короткометражный                        43\n",
       "фантастика                              32\n",
       "исторический                            23\n",
       "мюзикл                                  18\n",
       "мистика                                 17\n",
       "фэнтези                                 13\n",
       "биографический, драма                    6\n",
       "для взрослых                             5\n",
       "военный                                  4\n",
       "нуар                                     3\n",
       "боевик, драма                            3\n",
       "война, драма                             2\n",
       "исторический, приключения                2\n",
       "детектив, триллер                        2\n",
       "спорт                                    2\n",
       "мультфильмы, комедия                     2\n",
       "мультфильмы, приключения                 2\n",
       "триллер, драма                           2\n",
       "комедия, мелодрама                       2\n",
       "исторический, военный                    2\n",
       "ужасы, триллер                           2\n",
       "игровое шоу                              1\n",
       "приключения, фэнтези                     1\n",
       "мультфильмы, приключения, семейный       1\n",
       "комедия, фэнтези                         1\n",
       "мультфильмы, семейный                    1\n",
       "боевик, драма, триллер                   1\n",
       "мультфильмы, фэнтези                     1\n",
       "драма, мелодрама                         1\n",
       "мелодрама, исторический                  1\n",
       "аниме, фэнтези                           1\n",
       "спорт, драма                             1\n",
       "комедия, музыка                          1\n",
       "документальный, исторический             1\n",
       "ток-шоу                                  1\n",
       "исторический, драма                      1\n",
       "биографический, исторический             1\n",
       "реалити-шоу                              1\n",
       "драма, война                             1\n",
       "криминал                                 1\n",
       "музыкальный                              1\n",
       "криминал, драма                          1\n",
       "военный, исторический                    1\n",
       "мюзикл, комедия                          1\n",
       "фэнтези, приключения                     1\n",
       "боевик, криминал                         1\n",
       "детектив, драма                          1\n",
       "фантастика, ужасы                        1\n",
       "военный, драма                           1\n",
       "приключения, драма                       1\n",
       "мистика, драма                           1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['genre'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пример словаря для замены редких/устаревших жанров\n",
    "genre_mapping = {\n",
    "    \"нуар\": \"драма\",\n",
    "    \"вестерн\": \"боевик\",\n",
    "    \"мюзикл\": \"комедия\",\n",
    "    \"биография\": \"драма\",\n",
    "    \"исторический\": \"драма\",\n",
    "    \"эротика\": \"драма\",\n",
    "    \"артхаус\": \"драма\",\n",
    "    \"концерт\": \"музыка\",\n",
    "    'музыкальный': 'музыка',\n",
    "    \"ток-шоу\": \"документальный\",\n",
    "    \"экспериментальный\": \"драма\",\n",
    "    \"спортивный\": \"драма\",\n",
    "    \"семейный\": \"приключения\",\n",
    "    \"военный\": \"война\",\n",
    "    'реалити-шоу': 'документальный',\n",
    "    \"игровое шоу\": 'документальный',\n",
    "    \"фильм-катастрофа\": \"боевик\",\n",
    "    'аниме': 'мультфильмы',\n",
    "    'криминал': 'драма'\n",
    "}\n",
    "\n",
    "# Разделяем жанры\n",
    "df['genre_list'] = df['genre'].fillna('').apply(lambda x: [g.strip().lower() for g in x.split(',') if g.strip()])\n",
    "\n",
    "# Заменяем по словарю\n",
    "def map_genres(genres):\n",
    "    return [genre_mapping.get(g, g) for g in genres]\n",
    "\n",
    "df['genre_list'] = df['genre_list'].apply(map_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['genre'] = df['genre_list'].apply(lambda lst: ', '.join(sorted(set(lst))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genre\n",
       "драма                       5802\n",
       "комедия                     1815\n",
       "боевик                      1799\n",
       "документальный              1606\n",
       "мультфильмы                 1502\n",
       "биографический               803\n",
       "детектив                     777\n",
       "триллер                      441\n",
       "война                        382\n",
       "мелодрама                    206\n",
       "приключения                  202\n",
       "ужасы                        190\n",
       "музыка                        70\n",
       "короткометражный              43\n",
       "фантастика                    32\n",
       "мистика                       17\n",
       "фэнтези                       13\n",
       "биографический, драма          7\n",
       "война, драма                   7\n",
       "для взрослых                   5\n",
       "боевик, драма                  4\n",
       "мультфильмы, приключения       4\n",
       "драма, приключения             3\n",
       "приключения, фэнтези           2\n",
       "детектив, триллер              2\n",
       "триллер, ужасы                 2\n",
       "комедия, мелодрама             2\n",
       "драма, триллер                 2\n",
       "мультфильмы, фэнтези           2\n",
       "комедия, мультфильмы           2\n",
       "спорт                          2\n",
       "драма, мелодрама               2\n",
       "комедия, фэнтези               1\n",
       "боевик, драма, триллер         1\n",
       "комедия, музыка                1\n",
       "документальный, драма          1\n",
       "драма, спорт                   1\n",
       "детектив, драма                1\n",
       "ужасы, фантастика              1\n",
       "драма, мистика                 1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['genre'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('movies_list.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/polina/miniforge3/envs/fixed_env/lib/python3.10/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 493/493 [00:27<00:00, 18.17it/s]\n"
     ]
    }
   ],
   "source": [
    "embeddings = model.encode(df['description'].tolist(),show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.array(embeddings).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "index.add(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📖 Получение сюжетов с Википедии:   6%|▋         | 1016/15756 [15:58<3:51:42,  1.06it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 43\u001b[0m\n\u001b[1;32m     40\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     42\u001b[0m tqdm\u001b[38;5;241m.\u001b[39mpandas(desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m📖 Получение сюжетов с Википедии\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 43\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplot\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmovie_title\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprogress_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_plot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# --- Шаг 2: Объединённый текст для эмбеддингов ---\u001b[39;00m\n\u001b[1;32m     46\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfull_text\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplot\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniforge3/envs/fixed_env/lib/python3.10/site-packages/tqdm/std.py:917\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner\u001b[0;34m(df, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;66;03m# Apply the provided function (in **kwargs)\u001b[39;00m\n\u001b[1;32m    915\u001b[0m \u001b[38;5;66;03m# on the df using our wrapper (which provides bar updating)\u001b[39;00m\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_function\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    919\u001b[0m     t\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/miniforge3/envs/fixed_env/lib/python3.10/site-packages/pandas/core/series.py:4935\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4800\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4801\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4802\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4807\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4808\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4809\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4810\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4811\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4926\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4927\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4928\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4929\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4930\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4931\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4932\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4933\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4934\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 4935\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/fixed_env/lib/python3.10/site-packages/pandas/core/apply.py:1422\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1419\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1421\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1422\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/fixed_env/lib/python3.10/site-packages/pandas/core/apply.py:1502\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1500\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1501\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1502\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1503\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1507\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1508\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/miniforge3/envs/fixed_env/lib/python3.10/site-packages/pandas/core/base.py:925\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    923\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 925\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/fixed_env/lib/python3.10/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mpandas/_libs/lib.pyx:2999\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniforge3/envs/fixed_env/lib/python3.10/site-packages/tqdm/std.py:912\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    906\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    907\u001b[0m     \u001b[38;5;66;03m# update tbar correctly\u001b[39;00m\n\u001b[1;32m    908\u001b[0m     \u001b[38;5;66;03m# it seems `pandas apply` calls `func` twice\u001b[39;00m\n\u001b[1;32m    909\u001b[0m     \u001b[38;5;66;03m# on the first column/row to decide whether it can\u001b[39;00m\n\u001b[1;32m    910\u001b[0m     \u001b[38;5;66;03m# take a fast or slow code path; so stop when t.total==t.n\u001b[39;00m\n\u001b[1;32m    911\u001b[0m     t\u001b[38;5;241m.\u001b[39mupdate(n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mn \u001b[38;5;241m<\u001b[39m t\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 912\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 17\u001b[0m, in \u001b[0;36mget_plot\u001b[0;34m(title)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_plot\u001b[39m(title):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;66;03m# Добавляем задержку, чтобы избежать блокировки\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m         \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m         page \u001b[38;5;241m=\u001b[39m wiki\u001b[38;5;241m.\u001b[39mpage(title)\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;66;03m# Проверяем существование страницы с дополнительной защитой\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import faiss\n",
    "import time\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import wikipediaapi\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- Настройки Wikipedia ---\n",
    "USER_AGENT = \"MovieRecommendationBot/1.0 (https://example.com/contact)\"\n",
    "wiki = wikipediaapi.Wikipedia(language=\"ru\", user_agent=USER_AGENT)\n",
    "\n",
    "# --- Получение сюжета из Википедии ---\n",
    "def get_plot(title):\n",
    "    try:\n",
    "        # Добавляем задержку, чтобы избежать блокировки\n",
    "        time.sleep(0.5)\n",
    "        \n",
    "        page = wiki.page(title)\n",
    "        \n",
    "        # Проверяем существование страницы с дополнительной защитой\n",
    "        if not hasattr(page, 'pageid') or getattr(page, 'pageid', -1) == -1:\n",
    "            return \"\"\n",
    "            \n",
    "        # Ищем разделы с сюжетом (пробуем разные варианты названий)\n",
    "        section_titles = [\"Сюжет\", \"Содержание\", \"Фабула\", \"Plot\"]\n",
    "        for section_title in section_titles:\n",
    "            if section_title in page.sections:\n",
    "                return page.sections[section_title].text\n",
    "        \n",
    "        # Если раздел не найден, возвращаем пустую строку\n",
    "        return \"\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при получении сюжета для '{title}': {str(e)}\")\n",
    "        return \"\"\n",
    "\n",
    "# --- Шаг 1: Загрузка данных и добавление сюжетов ---\n",
    "df = pd.read_csv(\"movies_list.csv\")\n",
    "df[\"description\"] = df[\"description\"].fillna(\"\")\n",
    "\n",
    "tqdm.pandas(desc=\"📖 Получение сюжетов с Википедии\")\n",
    "df[\"plot\"] = df[\"movie_title\"].progress_apply(get_plot)\n",
    "\n",
    "# --- Шаг 2: Объединённый текст для эмбеддингов ---\n",
    "df[\"full_text\"] = df[\"description\"] + \"\\n\" + df[\"plot\"]\n",
    "\n",
    "# --- Шаг 3: Генерация эмбеддингов ---\n",
    "model = SentenceTransformer(\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "texts = df[\"full_text\"].tolist()\n",
    "embeddings = model.encode(texts, show_progress_bar=True)\n",
    "embeddings = np.array(embeddings).astype(\"float32\")\n",
    "\n",
    "# --- Шаг 4: Нормализация эмбеддингов (для косинусного сходства) ---\n",
    "embeddings /= np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
    "\n",
    "# --- Шаг 5: Создание FAISS индекса ---\n",
    "index = faiss.IndexFlatIP(embeddings.shape[1])  # IP == cosine sim (после нормализации)\n",
    "index.add(embeddings)\n",
    "\n",
    "# --- Шаг 6: Сохранение ---\n",
    "np.save(\"movie_vectors1.npy\", embeddings)\n",
    "faiss.write_index(index, \"index1.bin\")\n",
    "df.to_csv(\"movies_with_plots.csv\", index=False)\n",
    "\n",
    "print(\"✅ Готово! Всё сохранено.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Загрузка данных\n",
    "df = pd.read_csv(\"movies_with_plots.csv\")\n",
    "embeddings = np.load(\"movie_vectors1.npy\")\n",
    "index = faiss.read_index(\"index1.bin\")\n",
    "\n",
    "# Загрузка той же модели\n",
    "model = SentenceTransformer(\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_by_text(user_text, top_k=5):\n",
    "    query_vec = model.encode([user_text])\n",
    "    query_vec = query_vec / np.linalg.norm(query_vec, axis=1, keepdims=True)\n",
    "    scores, indices = index.search(query_vec.astype(\"float32\"), top_k)\n",
    "\n",
    "    print(f\"🎯 Рекомендации по описанию: '{user_text}'\\n\")\n",
    "    for i in indices[0]:\n",
    "        print(f\"→ {df.iloc[i]['movie_title']} ({df.iloc[i].get('year', 'год не указан')})\")\n",
    "        print(f\"Описание: {df.iloc[i]['description'][:200]}...\")\n",
    "        print(\"-\" * 50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend_by_text(\"киберпанк, мрачное будущее, виртуальная реальность\", top_k=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "GROQ_API_KEY=\"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\"\n",
    "# Для Groq Cloud\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "# === Настройки модели ===\n",
    "MODEL_NAME = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "GROQ_MODEL = \"mixtral-8x7b-32768\"  # или \"llama3-70b-8192\"\n",
    "\n",
    "# === Загрузка данных ===\n",
    "@st.cache_data\n",
    "def load_data():\n",
    "    df = pd.read_csv(\"movies_list.csv\")\n",
    "    return df\n",
    "\n",
    "# === Загрузка модели и индекса ===\n",
    "@st.cache_resource\n",
    "def load_model_and_index():\n",
    "    model = SentenceTransformer(MODEL_NAME)\n",
    "    vectors = np.load(\"movie_vectors.npy\")\n",
    "    index = faiss.read_index(\"index.bin\")\n",
    "    return model, index, vectors\n",
    "\n",
    "# === Функция поиска фильмов ===\n",
    "def find_similar_movies(query, model, index, df, top_k=5):\n",
    "    query_vec = model.encode([query]).astype('float32')\n",
    "    D, I = index.search(query_vec, top_k)\n",
    "    return df.iloc[I[0]]\n",
    "\n",
    "# === Подключение к Groq Cloud ===\n",
    "def get_groq_llm():\n",
    "    return ChatGroq(\n",
    "        model=GROQ_MODEL,\n",
    "        temperature=0.7,\n",
    "        max_tokens=1000,\n",
    "        timeout=None,\n",
    "        api_key=os.getenv(\"GROQ_API_KEY\")\n",
    "    )\n",
    "\n",
    "# === Форматирование результатов для LLM ===\n",
    "def format_docs(docs):\n",
    "    formatted = []\n",
    "    for i, row in docs.iterrows():\n",
    "        info = f\"\"\"\n",
    "{i+1}. **{row['movie_title']}** ({row.get('year', '?')})\n",
    "   Жанр: {row.get('genre', 'Не указан')}\n",
    "   Описание: {row.get('description', '')[:200]}...\n",
    "\"\"\"\n",
    "        formatted.append(info)\n",
    "    return \"\\n\".join(formatted)\n",
    "\n",
    "# === RAG цепочка с Groq Cloud ===\n",
    "def create_rag_chain(model, index, df):\n",
    "    llm = get_groq_llm()\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"Ты кинокритик с чувством юмора.\n",
    "Твоя задача: \n",
    "- Проанализировать фильмы из контекста\n",
    "- Дать шутливые, но точные рекомендации\n",
    "- Объяснить, почему они подходят под запрос\n",
    "- Можно добавить мемы или сравнения с известными фильмами\n",
    "\n",
    "Если фильмы не найдены — тоже скажи об этом, но с юмором 😊\"\"\"),\n",
    "        (\"human\", \"\"\"\n",
    "🔍 Запрос пользователя: \"{question}\"\n",
    "🎬 Вот фильмы, которые я нашёл:\n",
    "\n",
    "{context}\n",
    "\n",
    "💬 Ответ:\"\"\")\n",
    "    ])\n",
    "\n",
    "    def retrieve_and_format(query):\n",
    "        results = find_similar_movies(query, model, index, df, top_k=5)\n",
    "        if len(results) == 0:\n",
    "            return {\"context\": \"Ничего не нашлось...\", \"question\": query}\n",
    "        return {\"context\": format_docs(results), \"question\": query}\n",
    "\n",
    "    rag_chain = (\n",
    "        RunnablePassthrough(input=lambda x: x[\"query\"])\n",
    "        | retrieve_and_format\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    return rag_chain\n",
    "\n",
    "# === Streamlit UI ===\n",
    "import os\n",
    "os.environ[\"GROQ_API_KEY\"] = st.secrets.get(\"GROQ_API_KEY\", \"ваш_ключ\")\n",
    "\n",
    "st.set_page_config(page_title=\"🎬 Умные рекомендации\", layout=\"wide\")\n",
    "st.title(\"🤖 Умный поиск фильмов через Groq Cloud\")\n",
    "\n",
    "df = load_data()\n",
    "model, full_index, vectors = load_model_and_index()\n",
    "\n",
    "rag_chain = create_rag_chain(model, full_index, df)\n",
    "\n",
    "# === Ввод пользователя ===\n",
    "user_query = st.text_input(\"Введите запрос, например: 'Фильм про любовь в стиле аниме'\")\n",
    "if st.button(\"🔍 Найти и спросить ИИ\"):\n",
    "    if not user_query.strip():\n",
    "        st.warning(\"⚠️ Пожалуйста, введите запрос!\")\n",
    "    else:\n",
    "        with st.spinner(\"🧠 Думаю над этим...\"):\n",
    "            try:\n",
    "                answer = rag_chain.invoke({\"query\": user_query})\n",
    "                st.markdown(\"### 💬 Ответ от ИИ:\")\n",
    "                st.markdown(answer)\n",
    "            except Exception as e:\n",
    "                st.error(f\"❌ Ошибка: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/polina/miniforge3/envs/fixed_env/lib/python3.10/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Batches: 100%|██████████| 493/493 [00:25<00:00, 19.21it/s]\n"
     ]
    }
   ],
   "source": [
    "# Загрузка данных\n",
    "df = pd.read_csv(\"movies_list.csv\")\n",
    "\n",
    "# Предобработка описаний\n",
    "df[\"description\"] = df[\"description\"].fillna(\"\")\n",
    "\n",
    "# Загрузка модели\n",
    "model = SentenceTransformer(\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "\n",
    "# Генерация эмбеддингов\n",
    "embeddings = model.encode(df[\"description\"].tolist(), show_progress_bar=True)\n",
    "embeddings = np.array(embeddings).astype(\"float32\")\n",
    "\n",
    "# Нормализация для косинусного сходства\n",
    "embeddings /= np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
    "\n",
    "# Создание индекса на основе скалярного произведения (эквивалент косинусному сходству при нормализации)\n",
    "dimension = embeddings.shape[1]\n",
    "index = faiss.IndexFlatIP(dimension)  # Inner Product == Cosine similarity при нормализации\n",
    "index.add(embeddings)\n",
    "\n",
    "# Сохранение\n",
    "np.save(\"movie_vectors.npy\", embeddings)\n",
    "faiss.write_index(index, \"index.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎬 Название: С Новым годом!\n",
      "📄 Описание: Друзья собираются, чтобы отпраздновать Новый год. В ходе вечера они решают сыграть в игру и положить свои телефоны на общее обозрение. Во время игры раскроется много секретов, разобьются сердца и сломаются судьбы. С Новым годом!\n",
      "\n",
      "🎬 Название: О чем еще говорят мужчины\n",
      "📄 Описание: Так случилось, что почти весь день 31 декабря наши герои проводят вместе, Как они проводят время накануне Нового года? Разумеется, в разговорах. О чем? Во-первых, конечно, о женщинах – тема-то неисчерпаемая. А еще о…\n",
      "\n",
      "🎬 Название: Обратная связь\n",
      "📄 Описание: Канун Нового года. Старая компания снова в сборе и собирается весело отметить праздник. Но атмосфера в доме вновь накаляется до предела.\n",
      "\n",
      "🎬 Название: Декалог, три\n",
      "📄 Описание: Канун Рождества - ночь, когда вся семья вместе, и никто не хочет оставаться один. Эва соблазняет Януша, ее бывшего любовника, под любым предлогом выйти из дома и пробыть с ней всю ночь. Януш хочет вернуться домой, но Эва определенно решительна… \n",
      "\n",
      "🎬 Название: Джингл Белл трясёт!\n",
      "📄 Описание: Съемки андерграундной рождественской музыки. \n",
      "\n",
      "🎬 Название: Винни Пух и Рождество\n",
      "📄 Описание: Веселый, наполненный праздничным настроением мультфильм. Начинается история осенним днем, который неожиданно оказывается окончанием зимы. Как же так?! А куда подевалось Рождество, Новый Год? Как же зима могла пройти бесследно? Неужели столько игр и забав так и останутся лишь мечтой до следующего года? Катание на санках, лыжах, коньках, игра в снежки… И это только первая история из трех. \n",
      "\n",
      "🎬 Название: Реальная любовь в Нью-Йорке\n",
      "📄 Описание: В предновогоднем Нью-Йорке к празднику готовятся миллионы людей. У каждого своя мечта и вера в чудо. Некоторым судьбам суждено пересечься накануне Нового года ради истории любви - взаимной или безответной, радостной или мучительной, но всегда яркой и удивительной. В сюжете переплетаются истории нескольких персонажей - одна драматичнее другой. Молодой парень Джефф не может проработать и дня на новом месте из-за своей неуклюжести. Из-за этого он оказывается на улице и чуть не умирает от холода. Его спасает медсестра Элис, которая, не жалея себя, стремится помочь всем и каждому: то пациентам в госпитале, то координируя группу поддержки под названием Forgiveness, то раздавая еду бездомным в качестве волонтера. Бывший заключенный Марк, благодаря адвокату Джону Питеру, выходит из тюрьмы раньше срока и устраивается работать в русский ресторан «Зимний дворец», которым заправляет мастерски имитирующий русский акцент Тимофей. Домохозяйка бросает мужа-абьюзера и едет с детьми в Нью-Йорк…\n",
      "\n",
      "🎬 Название: Умершие\n",
      "📄 Описание: Экранизация одноименного рассказа Джеймса Джойса – настоящего шедевра о том, как один рождественский вечер может изменить все, перевернув взгляд на жизнь и, конечно, смерть. На званом ужине в честь праздника чета Конрой часто ссорится, а по возвращении домой уставшая жена рассказывает мужу о первом ухажере – подростке, который погиб из-за любви к ней. Так в снежный рождественский вечер герой со слезами на глазах понимает разницу между жизнью и существованием.\n",
      "\n",
      "🎬 Название: Ужасающий 3\n",
      "📄 Описание: Действие третьей части хоррора развернётся в рождественский сочельник.\n"
     ]
    }
   ],
   "source": [
    "# Запрос пользователя\n",
    "user_query = \"Новогодняя ночь\"\n",
    "query_vector = model.encode([user_query],convert_to_numpy=True).astype(\"float32\")\n",
    "\n",
    "# Векторизуем запрос\n",
    "#query_embedding = model.encode([user_query])\n",
    "\n",
    "# Считаем схожесть запроса с каждым сериалом\n",
    "#similarities = cosine_similarity(query_embedding, embeddings)[0]  # получаем 1D-массив\n",
    "\n",
    "# Получим индексы топ-5 самых похожих сериалов\n",
    "#top_n = 5\n",
    "#top_indices = similarities.argsort()[-top_n:][::-1]  # сортировка по убыванию\n",
    "\n",
    "# Выводим названия и описания похожих сериалов\n",
    "# for i in top_indices:\n",
    "#     print(f\"\\n🎬 Название: {df.iloc[i]['tvshow_title']}\")\n",
    "#     print(f\"📄 Описание: {df.iloc[i]['description']}\")\n",
    "#     print(f\"🔍 Схожесть: {similarities[i]:.3f}\")\n",
    "\n",
    "k = 9\n",
    "distances, indices = index.search(query_vector, k)\n",
    "\n",
    "# Выводим результаты\n",
    "for i in indices[0]:\n",
    "    print(f\"\\n🎬 Название: {df.iloc[i]['movie_title']}\")\n",
    "    print(f\"📄 Описание: {df.iloc[i]['description']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fixed_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
