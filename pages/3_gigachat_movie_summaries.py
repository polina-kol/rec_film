import streamlit as st
import pandas as pd
import numpy as np
from sentence_transformers import SentenceTransformer
import faiss
from langchain_groq import ChatGroq
from langchain_core.messages import SystemMessage, HumanMessage

# === –í–ê–ñ–ù–û: API –∫–ª—é—á –ø—Ä–æ–ø–∏—Å–∞–Ω –∑–¥–µ—Å—å ===
GROQ_API_KEY = "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"

MODEL_NAME = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
GROQ_MODEL = "deepseek-r1-distill-llama-70b"

@st.cache_data
def load_data():
    return pd.read_csv("movies_list.csv")

@st.cache_resource
def load_model_and_index():
    model = SentenceTransformer(MODEL_NAME)
    vectors = np.load("movie_vectors.npy")
    index = faiss.read_index("index.bin")
    return model, index, vectors

def find_similar_movies(query, model, index, df, top_k=5):
    query_vec = model.encode([query]).astype('float32')
    D, I = index.search(query_vec, top_k)
    return df.iloc[I[0]]

def format_movies_for_prompt(docs):
    lines = []
    for i, row in docs.iterrows():
        lines.append(f"{i+1}. {row['movie_title']} ({row.get('year', '?')}) ‚Äî –∂–∞–Ω—Ä: {row.get('genre', '–Ω–µ —É–∫–∞–∑–∞–Ω')}\n–û–ø–∏—Å–∞–Ω–∏–µ: {row.get('description', '')[:200]}...")
    return "\n".join(lines)

def get_groq_llm():
    return ChatGroq(
        model=GROQ_MODEL,
        temperature=0.7,
        max_tokens=1500,
        api_key=GROQ_API_KEY
    )

st.title("üé¨ –ü–æ–∏—Å–∫ —Ñ–∏–ª—å–º–æ–≤ + —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ DeepSeek")

df = load_data()
model, index, vectors = load_model_and_index()

user_query = st.text_input("–í–≤–µ–¥–∏—Ç–µ –∑–∞–ø—Ä–æ—Å, –Ω–∞–ø—Ä–∏–º–µ—Ä: '–§–∏–ª—å–º –ø—Ä–æ –ª—é–±–æ–≤—å –≤ —Å—Ç–∏–ª–µ –∞–Ω–∏–º–µ'")

if st.button("–ü–æ–ª—É—á–∏—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏"):
    if not user_query.strip():
        st.warning("–í–≤–µ–¥–∏—Ç–µ –∑–∞–ø—Ä–æ—Å!")
    else:
        with st.spinner("–ò—â—É –ø–æ—Ö–æ–∂–∏–µ —Ñ–∏–ª—å–º—ã..."):
            try:
                # 1. –ü–æ–∏—Å–∫ –ø–æ –±–∞–∑–µ
                similar_movies = find_similar_movies(user_query, model, index, df, top_k=5)

                if similar_movies.empty:
                    st.info("–ü–æ –≤–∞—à–µ–º—É –∑–∞–ø—Ä–æ—Å—É –Ω–µ –Ω–∞–π–¥–µ–Ω–æ —Ñ–∏–ª—å–º–æ–≤ –≤ –±–∞–∑–µ.")
                else:
                    st.markdown("### üéû –ù–∞–π–¥–µ–Ω–Ω—ã–µ —Ñ–∏–ª—å–º—ã –∏–∑ –±–∞–∑—ã:")
                    for i, row in similar_movies.iterrows():
                        st.markdown(f"**{row['movie_title']}** ({row.get('year', '?')}) ‚Äî –∂–∞–Ω—Ä: {row.get('genre', '–Ω–µ —É–∫–∞–∑–∞–Ω')}\n\n{row.get('description', '')[:300]}...")

                # 2. –û—Ç–¥–µ–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å –∫ DeepSeek LLM –Ω–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ (–±–µ–∑ –ø—Ä–∏–≤—è–∑–∫–∏ –∫ –±–∞–∑–µ)
                llm = get_groq_llm()
                system_msg = SystemMessage(content=(
                    "–¢—ã –∫–∏–Ω–æ–∫—Ä–∏—Ç–∏–∫, –æ—Ç–≤–µ—á–∞–µ—à—å —Ç–æ–ª—å–∫–æ –ø–æ-—Ä—É—Å—Å–∫–∏, —Å —é–º–æ—Ä–æ–º –∏ —à—É—Ç–∫–∞–º–∏. "
                    "–î–∞–π –∑–∞–±–∞–≤–Ω—ã–µ –∏ —Ç–æ—á–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ —Ñ–∏–ª—å–º–æ–≤, –æ—Å–Ω–æ–≤—ã–≤–∞—è—Å—å –Ω–∞ –∑–∞–ø—Ä–æ—Å–µ, "
                    "–Ω–æ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ –±–∞–∑—É, –∞ —Å–≤–æ–∏ –∑–Ω–∞–Ω–∏—è."
                ))
                human_msg = HumanMessage(content=f"–ó–∞–ø—Ä–æ—Å: {user_query}\n\n–î–∞–π —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ —Ñ–∏–ª—å–º–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–¥—Ö–æ–¥—è—Ç –ø–æ–¥ —ç—Ç–æ—Ç –∑–∞–ø—Ä–æ—Å.")

                answer = llm.invoke([system_msg, human_msg]).content

                st.markdown("### üí¨ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –æ—Ç DeepSeek (–±–µ–∑ –±–∞–∑—ã):")
                st.markdown(answer)

            except Exception as e:
                st.error(f"–û—à–∏–±–∫–∞: {e}")
